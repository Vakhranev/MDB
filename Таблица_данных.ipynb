{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+AKYQ9bxwYfpDOEBgRyMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/MDB/blob/main/%D0%A2%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import csv\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLQgb0uquhmN",
        "outputId": "516b28c2-6d8c-4584-bcb3-047d25869647"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# распаковываем архив\n",
        "fantasy_zip = zipfile.ZipFile('Transcribed data txt Summer STANDARDIZED 2017 2018 2019 2020.zip')\n",
        "fantasy_zip.extractall()\n",
        "fantasy_zip.close()"
      ],
      "metadata": {
        "id": "66YQ98iRTl_j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path =\"Transcribed data txt Summer STANDARDIZED 2017 2018 2019 2020\"\n",
        "filelist = []\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "    if str(file)[-3:]=='txt':\n",
        "      filelist.append(os.path.join(root,file))\n",
        "\n",
        "print(len(filelist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBaVV3h8T_a6",
        "outputId": "15f28b18-9b81-453e-bd2f-94a59af45a1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# создаём csv-файл и пока вносим в него только названия колонок\n",
        "with open('mdb_files.csv', 'w') as csvfile:\n",
        "    filewriter = csv.writer(csvfile, delimiter=';', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    filewriter.writerow(['File Name', 'Length', 'First Name', 'Last Name', 'Entry/Exit', 'Mark', 'Year'])\n",
        "\n",
        "for name in filelist:\n",
        "    # Извлекаем год из элемента с индексом 1 в списке filelist\n",
        "    Year = re.findall(r'\\d{4}', name.split(\"/\")[1])[0] if re.findall(r'\\d{4}', name.split(\"/\")[1]) else ''\n",
        "\n",
        "    # вытаскиваем названия файлов из архива\n",
        "    FileName = re.split(r'/', name)[-1]\n",
        "\n",
        "    # Убираем год из имени файла\n",
        "    Names_of_file = re.sub(r'\\d', '', FileName)\n",
        "\n",
        "    # Заменяем пробельные символы на нижние подчёркивания\n",
        "    Names_of_file = re.sub(r'\\s+(?!\\.)', '_', Names_of_file)\n",
        "\n",
        "    # Удаляем повторяющиеся подчёркивания\n",
        "    Names_of_file = re.sub(r'(?<!_)_(?!_)', '_', Names_of_file)\n",
        "\n",
        "    # Заменяем последовательности подчёркиваний на одно подчёркивание\n",
        "    Names_of_file = re.sub(r'_{2,}', '_', Names_of_file)\n",
        "\n",
        "    # Удаляем подчёркивания в начале и конце строки\n",
        "    Names_of_file = re.sub(r'^_+|_+$', '', Names_of_file)\n",
        "\n",
        "    # экранируем специальные символы в строке перед использованием в регулярном выражении\n",
        "    Names_of_file_escaped = re.escape(Names_of_file)\n",
        "\n",
        "    # разбиваем названия файла по нижним подчёркиваниям и удаляем последний элемент списка\n",
        "    List_with_names = Names_of_file_escaped.split(\"_\")[:-1]\n",
        "\n",
        "    # проверяем, если последний элемент List_with_names равен 'ST', удаляем его\n",
        "    if List_with_names[-1] == 'ST':\n",
        "        List_with_names.pop()\n",
        "\n",
        "    # делаем строчный регистр и группируем имена правильно, если имён двое, например\n",
        "    FN = List_with_names[0].lower()\n",
        "    if len(List_with_names) > 3:\n",
        "        List_with_names[0] = List_with_names[0] + \" \" + List_with_names[1]\n",
        "        List_with_names[1] = List_with_names[2]\n",
        "        List_with_names[2] = List_with_names[3]\n",
        "\n",
        "    List_with_names[0] = List_with_names[0].lower()\n",
        "    List_with_names[1] = List_with_names[1].lower()\n",
        "\n",
        "    df = pd.read_csv('metadata.csv', sep=',')\n",
        "    df.index = np.arange(1, len(df) + 1)\n",
        "\n",
        "    # в именах из файла тоже делаем строчный регистр\n",
        "    # (потому что в названиях файла и таблице не везде заглавные буквы совпадали)\n",
        "    df['Last_Name'] = df['Last_Name'].str.lower()\n",
        "    df['First_Name'] = df['First_Name'].str.lower()\n",
        "\n",
        "    # проверяем, совпадают ли имена в названиях файла с именами таблицы\n",
        "    df1 = df[df[\"First_Name\"].str.contains(FN)]\n",
        "    df1 = df1[df1[\"Last_Name\"].str.contains(List_with_names[1])]\n",
        "\n",
        "    if df1.empty:\n",
        "        df1 = df[df[\"Last_Name\"].str.contains(FN)]\n",
        "        df1 = df1[df1[\"First_Name\"].str.contains(List_with_names[1])]\n",
        "    if df1.empty:\n",
        "        df1 = df.query(\"First_Name == @List_with_names[0]\")\n",
        "        df1 = df1.query(\"Last_Name == @List_with_names[1]\")\n",
        "    if df1.empty:\n",
        "        df1 = df.query(\"Last_Name == @List_with_names[0]\")\n",
        "        df1 = df1.query(\"First_Name == @List_with_names[1]\")\n",
        "\n",
        "    # проверяем не содержат ли имена в таблице нижние подчёркивания вместо каких-нибудь символов\n",
        "    if df1.empty:\n",
        "        df1 = df[df[\"Last_Name\"].str.contains('_')]\n",
        "        df1 = df1[df1[\"First_Name\"].str.contains(List_with_names[0])]\n",
        "\n",
        "    # вытаскиваем оценки\n",
        "    if List_with_names[2] == 'Entry':\n",
        "        mark = str(df1['Entry'])\n",
        "        mark = re.split(r'\\s', mark)[-5]\n",
        "    else:\n",
        "        mark = str(df1['Exit'])\n",
        "        mark = re.split(r'\\s', mark)[-5]\n",
        "\n",
        "    # проверяем совпадает ли год из имени файла с годом в поле Year в данных из файла metadata\n",
        "    if ' Year' in df1.columns:\n",
        "        # print(str(Year) + ' и ' + str(df1[' Year'].iloc[0]))\n",
        "        if Year == str(df1[' Year'].iloc[0]):\n",
        "            # print(df1[' Year'].iloc[0])\n",
        "            # загоняем всё в новый файл\n",
        "            with open(name, 'r') as file:\n",
        "                lines_in_file = file.read()\n",
        "\n",
        "                nltk_tokens = nltk.word_tokenize(lines_in_file)\n",
        "                nltk_tokens = \" \".join(word for word in nltk_tokens if word not in ('!', '.', ':', ',', '–', '?', '(', ')', ';', '`', '<', '>'))\n",
        "                nltk_tokens = nltk.word_tokenize(nltk_tokens)\n",
        "                with open('mdb_files.csv', 'a') as csvfile:\n",
        "                    filewriter = csv.writer(csvfile, delimiter=';', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "                    filewriter.writerow([FileName, len(nltk_tokens), List_with_names[0], List_with_names[1], List_with_names[2], mark, Year])\n",
        "    else:\n",
        "        print(\"Столбец 'Year' не существует в данных из файла metadata.csv\")"
      ],
      "metadata": {
        "id": "7AqLQDDnW4Bs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sz8RBvjpYUFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}